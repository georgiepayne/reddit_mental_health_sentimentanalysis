{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgiepayne/reddit_mental_health_sentimentanalysis/blob/master/reddit_mental_health.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install nltk  # Package used for prepocessing data\n",
        "!pip install pyspellchecker # Package used to correct spelling"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ophDqP273K5",
        "outputId": "4d270779-7077-400e-fc5b-de69433e405b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  # To help get a list of stopwords to exclude\n",
        "nltk.download('stopwords') # The word bank we references to delete stopwords\n",
        "from collections import Counter # To help count the frequent words\n",
        "from nltk.stem.porter import PorterStemmer  # To help stem words\n",
        "from spellchecker import SpellChecker  # To help correct spelling\n",
        "import re  # To help remove urls\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "qTgiVvIA_Nxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d634a20-81c3-42d7-d465-28d7f304dfaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T8BdUiQf7WWI",
        "outputId": "0a1c450c-faaf-4e5e-c631-93a6d4cad308",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 author                                               body  \\\n",
              "0   HotConversation1273  A few months ago I was accepted into this full...   \n",
              "1            snorefestt  Hey guys, I was curious if anyone else has the...   \n",
              "2                etyf12   \\n\\ni have 6 exams in the next 2 weeks one of...   \n",
              "3     GetHairOrDieTryin  Is there anyone out there that is struggling w...   \n",
              "4          ZeroTransPat  Whenever I get hungry, I never eat because I d...   \n",
              "5             [deleted]                                                      \n",
              "6   Used_Inspection2618  I’m on 20 mg of Lexapro and 50 mg Vyvanse and ...   \n",
              "7         TheToastyToad  I've recently had a big lifestyle change, with...   \n",
              "8        Field-cave1519  I'm a newly diagnosed 42 yr old female, who st...   \n",
              "9  Away_Entertainment29  TL;DR - rough time titrating on concerta for t...   \n",
              "\n",
              "                created_utc      id  num_comments  score subreddit  \\\n",
              "0  2021-12-22T18:32:56.000Z  rmbjwb             1      1      ADHD   \n",
              "1  2021-12-22T18:24:25.000Z  rmbd1y             3      5      ADHD   \n",
              "2  2021-12-22T18:22:52.000Z  rmbbvu             1      2      ADHD   \n",
              "3  2021-12-22T18:20:35.000Z  rmba1t             3      2      ADHD   \n",
              "4  2021-12-22T18:18:47.000Z  rmb8lm             2      1      ADHD   \n",
              "5  2021-12-22T18:18:19.000Z  rmb88p             1      1      ADHD   \n",
              "6  2021-12-22T18:15:52.000Z  rmb6f2             4      1      ADHD   \n",
              "7  2021-12-22T18:13:15.000Z  rmb47u             1      2      ADHD   \n",
              "8  2021-12-22T18:11:07.000Z  rmb2i8             1      1      ADHD   \n",
              "9  2021-12-22T18:09:50.000Z  rmb1ib             1      1      ADHD   \n",
              "\n",
              "                                               title  upvote_ratio  \\\n",
              "0    I get extremely anxious if I’m not working 24/7           1.0   \n",
              "1  I can't will myself to clean my own house, but...           1.0   \n",
              "2                                   i need some help           1.0   \n",
              "3                              Anyone up for a chat?           1.0   \n",
              "4                     Figuring out what to eat sucks           1.0   \n",
              "5             Watching movies at x1.5 playback speed           1.0   \n",
              "6                            Drinking while on meds?           1.0   \n",
              "7                    Using Christmas to take a break           1.0   \n",
              "8  Does everyone get the euphoria feeling when th...           1.0   \n",
              "9                      Xaggatin: zoned out and angry           1.0   \n",
              "\n",
              "                                                 url  \n",
              "0  https://www.reddit.com/r/ADHD/comments/rmbjwb/...  \n",
              "1  https://www.reddit.com/r/ADHD/comments/rmbd1y/...  \n",
              "2  https://www.reddit.com/r/ADHD/comments/rmbbvu/...  \n",
              "3  https://www.reddit.com/r/ADHD/comments/rmba1t/...  \n",
              "4  https://www.reddit.com/r/ADHD/comments/rmb8lm/...  \n",
              "5  https://www.reddit.com/r/ADHD/comments/rmb88p/...  \n",
              "6  https://www.reddit.com/r/ADHD/comments/rmb6f2/...  \n",
              "7  https://www.reddit.com/r/ADHD/comments/rmb47u/...  \n",
              "8  https://www.reddit.com/r/ADHD/comments/rmb2i8/...  \n",
              "9  https://www.reddit.com/r/ADHD/comments/rmb1ib/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49c34f75-b6d7-47ec-a62f-463ed7077647\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>id</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HotConversation1273</td>\n",
              "      <td>A few months ago I was accepted into this full...</td>\n",
              "      <td>2021-12-22T18:32:56.000Z</td>\n",
              "      <td>rmbjwb</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>I get extremely anxious if I’m not working 24/7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmbjwb/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>snorefestt</td>\n",
              "      <td>Hey guys, I was curious if anyone else has the...</td>\n",
              "      <td>2021-12-22T18:24:25.000Z</td>\n",
              "      <td>rmbd1y</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>I can't will myself to clean my own house, but...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmbd1y/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>etyf12</td>\n",
              "      <td>\\n\\ni have 6 exams in the next 2 weeks one of...</td>\n",
              "      <td>2021-12-22T18:22:52.000Z</td>\n",
              "      <td>rmbbvu</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>i need some help</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmbbvu/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GetHairOrDieTryin</td>\n",
              "      <td>Is there anyone out there that is struggling w...</td>\n",
              "      <td>2021-12-22T18:20:35.000Z</td>\n",
              "      <td>rmba1t</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Anyone up for a chat?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmba1t/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ZeroTransPat</td>\n",
              "      <td>Whenever I get hungry, I never eat because I d...</td>\n",
              "      <td>2021-12-22T18:18:47.000Z</td>\n",
              "      <td>rmb8lm</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Figuring out what to eat sucks</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmb8lm/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td></td>\n",
              "      <td>2021-12-22T18:18:19.000Z</td>\n",
              "      <td>rmb88p</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Watching movies at x1.5 playback speed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmb88p/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Used_Inspection2618</td>\n",
              "      <td>I’m on 20 mg of Lexapro and 50 mg Vyvanse and ...</td>\n",
              "      <td>2021-12-22T18:15:52.000Z</td>\n",
              "      <td>rmb6f2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Drinking while on meds?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmb6f2/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TheToastyToad</td>\n",
              "      <td>I've recently had a big lifestyle change, with...</td>\n",
              "      <td>2021-12-22T18:13:15.000Z</td>\n",
              "      <td>rmb47u</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Using Christmas to take a break</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmb47u/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Field-cave1519</td>\n",
              "      <td>I'm a newly diagnosed 42 yr old female, who st...</td>\n",
              "      <td>2021-12-22T18:11:07.000Z</td>\n",
              "      <td>rmb2i8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Does everyone get the euphoria feeling when th...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmb2i8/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Away_Entertainment29</td>\n",
              "      <td>TL;DR - rough time titrating on concerta for t...</td>\n",
              "      <td>2021-12-22T18:09:50.000Z</td>\n",
              "      <td>rmb1ib</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>Xaggatin: zoned out and angry</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.reddit.com/r/ADHD/comments/rmb1ib/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49c34f75-b6d7-47ec-a62f-463ed7077647')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49c34f75-b6d7-47ec-a62f-463ed7077647 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49c34f75-b6d7-47ec-a62f-463ed7077647');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9fc17391-bced-44f8-b9df-4ee0b5f804fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fc17391-bced-44f8-b9df-4ee0b5f804fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9fc17391-bced-44f8-b9df-4ee0b5f804fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "ds_load = load_dataset(\"solomonk/reddit_mental_health_posts\")\n",
        "print(type(ds_load['train']))\n",
        "\n",
        "df = pd.DataFrame(ds_load['train'])\n",
        "\n",
        "# Replace the body with a title any time it gets deleted or removed\n",
        "\n",
        "# Strip any whitespace from the `body` column\n",
        "body_stripped = df['body'].str.strip()\n",
        "\n",
        "# Check if the `body` contains `[deleted]` or `[removed]`\n",
        "is_deleted = body_stripped.isin(['[deleted]', '[removed]'])\n",
        "\n",
        "# Replace the entry in body with the entry in title\n",
        "df.loc[is_deleted, 'body'] = \"\"\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions that the preprocess function calls\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Helper functions that the preprocess function calls\n",
        "def remove_stopwords(text):\n",
        "\n",
        "  # Get the stopwords from from the english language\n",
        "  # This data is found in the stopwords libarary\n",
        "  STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "  # Split the string into and array of words\n",
        "  words = str(text).split()\n",
        "\n",
        "  filtered = []  # To keep track of the filtered words\n",
        "\n",
        "  # Loop through the words array\n",
        "  for word in words:\n",
        "\n",
        "    # Append any words not in the STOPWORDS array\n",
        "    filtered.append(word) if word not in STOPWORDS else None\n",
        "\n",
        "  # Make the final string by adding spaces between all stop words\n",
        "  cleaned_string = \" \".join(filtered)\n",
        "  return cleaned_string\n",
        "\n",
        "def remove_frequent_and_rare(data, top_n=10, min_frequency=10):\n",
        "  counter = Counter()  # make a counter\n",
        "\n",
        "  # Count words from both 'body' and 'title' columns\n",
        "  for col in [\"body\", \"title\"]:\n",
        "    # get entrues as strings\n",
        "    data[col] = data[col].astype(str)\n",
        "\n",
        "    # update counter for each word\n",
        "    for text in data[col]:\n",
        "      for word in text.split():\n",
        "        counter[word] +=1\n",
        "\n",
        "  # Get the top N most frequent words\n",
        "  most_frequent_words = {word for word, _ in counter.most_common(top_n)}\n",
        "\n",
        "  # Get the rare words (show up less than min_frequency)\n",
        "  rare_words = {word for word, count in counter.items() if count < min_frequency}\n",
        "\n",
        "  # Combine frequent and rare words to be filtered out\n",
        "  words_to_filter = most_frequent_words.union(rare_words)\n",
        "\n",
        "  # Filter the 'body' and 'title' columns\n",
        "  for col in [\"body\", \"title\"]:\n",
        "    filtered_column = []\n",
        "    for text in data[col]:\n",
        "      words = text.split()\n",
        "      filtered_words = [word for word in words if word not in words_to_filter]\n",
        "      filtered_column.append(\" \".join(filtered_words))\n",
        "\n",
        "    # Update the DataFrame column\n",
        "    data[col] = filtered_column\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def stem_words(text):\n",
        "  stemmer = PorterStemmer()\n",
        "  words = text.split()\n",
        "\n",
        "  # Store the filtered words in the array\n",
        "  filtered = []\n",
        "  # Go through the text\n",
        "  for word in words:\n",
        "    # And stem each words\n",
        "    filtered.append(stemmer.stem(word))\n",
        "\n",
        "  cleaned_string = \" \".join(filtered)\n",
        "  return cleaned_string\n",
        "\n",
        "def expand_abbreviations(text):\n",
        "\n",
        "  # Turn a the text file containing abbreviations into a data frame\n",
        "  path = \"abbreviations.txt\"\n",
        "  df = pd.read_csv(path, sep=\"=\", names=[\"abbreviation\", \"expanded\"], header=None)\n",
        "\n",
        "  abbreviations_dictionary = {}\n",
        "\n",
        "  # I work with arrays better so I'm converting it into one\n",
        "  data_array = df[[\"abbreviation\", \"expanded\"]].values\n",
        "\n",
        "  # Fill up the dictionary\n",
        "  for row in data_array:\n",
        "    abbreviation = row[0]\n",
        "    expanded = row[1]\n",
        "    abbreviations_dictionary[abbreviation] = expanded\n",
        "\n",
        "  expanded_text = []\n",
        "\n",
        "  words = text.split()\n",
        "\n",
        "  # Go through the text\n",
        "  for word in words:\n",
        "    # Check if the abbreviation matches anything in the dictionary\n",
        "    if word in abbreviations_dictionary:\n",
        "      expanded_text.append( abbreviations_dictionary[word] )\n",
        "    else:\n",
        "      expanded_text.append(word)\n",
        "\n",
        "  cleaned_string = \" \".join(expanded_text)\n",
        "  return cleaned_string\n",
        "\n",
        "\n",
        "def remove_urls(text):\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "svrLWCr3wVfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function the cleans the the input data\n",
        "def preprocess(data):\n",
        "  # Set everything to lowercase\n",
        "  data[\"body\"] = data[\"body\"].str.lower()\n",
        "  data[\"title\"] = data[\"title\"].str.lower()\n",
        "\n",
        "  # Remove all punctuation\n",
        "  data[\"body\"] = data[\"body\"].apply(lambda text: remove_punctuation(text) if text is not None else text)\n",
        "  data[\"title\"] = data[\"title\"].apply(lambda text: remove_punctuation(text) if text is not None else text)\n",
        "\n",
        "  # remove stop words\n",
        "  data[\"body\"] = data[\"body\"].apply(lambda text: remove_stopwords(text) if text is not None else text)\n",
        "  data[\"title\"] = data[\"title\"].apply(lambda text: remove_stopwords(text) if text is not None else text)\n",
        "\n",
        "  # remove frequent words and rare words\n",
        "  data = remove_frequent_and_rare(data)\n",
        "\n",
        "  # apply stemming\n",
        "  data[\"body\"] = data[\"body\"].apply(lambda text: stem_words(text) if text is not None else text)\n",
        "  data[\"title\"] = data[\"title\"].apply(lambda text: stem_words(text) if text is not None else text)\n",
        "\n",
        "  # expand abbreviations\n",
        "  data[\"body\"] = data[\"body\"].apply(lambda text: expand_abbreviations(text) if text is not None else text)\n",
        "  data[\"title\"] = data[\"title\"].apply(lambda text: expand_abbreviations(text) if text is not None else text)\n",
        "\n",
        "  # remove urls\n",
        "  data[\"body\"] = data[\"body\"].apply(lambda text: remove_urls(text) if text is not None else text)\n",
        "  data[\"title\"] = data[\"title\"].apply(lambda text: remove_urls(text) if text is not None else text)\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "preprocessed_df = preprocess(df)\n",
        "print(preprocessed_df.head())"
      ],
      "metadata": {
        "id": "ejzLgTRDEHY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befe6a49-1818-4649-e5fd-cb3d338366e9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                author                                               body  \\\n",
            "0  HotConversation1273  month ago accept full softwar engin it’ made r...   \n",
            "1           snorefestt  hey guy curiou anyon els issu apart fuck exagg...   \n",
            "2               etyf12  6 exam next 2 week one monday havent studi ove...   \n",
            "3    GetHairOrDieTryin  anyon struggl addadhd that’ interest chat bit ...   \n",
            "4         ZeroTransPat  whenev hungri never eat eat end pizza easi obv...   \n",
            "\n",
            "                created_utc      id  num_comments  score subreddit  \\\n",
            "0  2021-12-22T18:32:56.000Z  rmbjwb             1      1      ADHD   \n",
            "1  2021-12-22T18:24:25.000Z  rmbd1y             3      5      ADHD   \n",
            "2  2021-12-22T18:22:52.000Z  rmbbvu             1      2      ADHD   \n",
            "3  2021-12-22T18:20:35.000Z  rmba1t             3      2      ADHD   \n",
            "4  2021-12-22T18:18:47.000Z  rmb8lm             2      1      ADHD   \n",
            "\n",
            "                                               title  upvote_ratio  \\\n",
            "0                             extrem anxiou work 247           1.0   \n",
            "1  cant clean hous incred motiv clean girlfriend ...           1.0   \n",
            "2                                          need help           1.0   \n",
            "3                                         anyon chat           1.0   \n",
            "4                                     figur eat suck           1.0   \n",
            "\n",
            "                                                 url  \n",
            "0  https://www.reddit.com/r/ADHD/comments/rmbjwb/...  \n",
            "1  https://www.reddit.com/r/ADHD/comments/rmbd1y/...  \n",
            "2  https://www.reddit.com/r/ADHD/comments/rmbbvu/...  \n",
            "3  https://www.reddit.com/r/ADHD/comments/rmba1t/...  \n",
            "4  https://www.reddit.com/r/ADHD/comments/rmb8lm/...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df.to_csv('preprocessed_data.csv', index=False)"
      ],
      "metadata": {
        "id": "TMPxdEq50s9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df = pd.read_csv('preprocessed_data.csv')\n",
        "preprocessed_df['body'] = preprocessed_df['body'].fillna('')\n",
        "preprocessed_df['title'] = preprocessed_df['title'].fillna('')"
      ],
      "metadata": {
        "id": "7ob3wNaexv7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = preprocessed_df[['body', 'title']]   # Input the model uses to make a prediction\n",
        "y = preprocessed_df['subreddit']         # Metal health issue the model should predict\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "uODUKPvh_PuH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn count vectorizer\n",
        "\n",
        "def vectorize(data):\n",
        "  vectorizer = CountVectorizer()\n",
        "\n",
        "  # Combine the body and title text into a single column\n",
        "  combined_data = data['body'] + \" \" + data['title']\n",
        "\n",
        "  # Fit and transform the combined text\n",
        "  vector = vectorizer.fit_transform(combined_data)\n",
        "\n",
        "  return vector\n",
        "\n",
        "X_train_vector = vectorize(X_train)"
      ],
      "metadata": {
        "id": "NauDetRH0xj_"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}